{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05c71603-8c25-4e7c-8229-f4d6c0d6b505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from skimage import io, color\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.measure import regionprops\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11324373-27ae-46ae-b7ee-e5ab786614d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for all datasets\n",
    "base_path = \"D:/work/ai&ml/projects/FNN-signature verification/temp/Dataset\"\n",
    "datasets = ['dataset1', 'dataset2', 'dataset3', 'dataset4']  # Your dataset folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df99353f-f4d1-4ff6-879f-30f437e7bb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing and Feature Extraction Functions (as before)\n",
    "def rgb2gray(img):\n",
    "    # Check if the image already has a single channel (grayscale)\n",
    "    if len(img.shape) == 2:  # Already grayscale\n",
    "        return img\n",
    "    return color.rgb2gray(img)  # Convert to grayscale if it's an RGB image\n",
    "\n",
    "def greybin(img):\n",
    "    blur_radius = 0.8\n",
    "    img = ndimage.gaussian_filter(img, blur_radius)\n",
    "    thres = threshold_otsu(img)\n",
    "    binimg = img > thres\n",
    "    return np.logical_not(binimg)\n",
    "\n",
    "def preproc(img):\n",
    "    gray = rgb2gray(img)\n",
    "    binimg = greybin(gray)\n",
    "    r, c = np.where(binimg)\n",
    "    return binimg[r.min():r.max(), c.min():c.max()]\n",
    "\n",
    "def Ratio(img):\n",
    "    return np.sum(img) / img.size\n",
    "\n",
    "def Centroid(img):\n",
    "    rows, cols = np.nonzero(img)\n",
    "    centroid = np.mean(np.stack([rows, cols], axis=1), axis=0)\n",
    "    return centroid[0] / img.shape[0], centroid[1] / img.shape[1]\n",
    "\n",
    "def EccentricitySolidity(img):\n",
    "    props = regionprops(img.astype(int))\n",
    "    return props[0].eccentricity, props[0].solidity\n",
    "\n",
    "def SkewKurtosis(img):\n",
    "    h, w = img.shape\n",
    "    x = np.arange(w)\n",
    "    y = np.arange(h)\n",
    "    xp = np.sum(img, axis=0)\n",
    "    yp = np.sum(img, axis=1)\n",
    "    cx = np.sum(x * xp) / np.sum(xp)\n",
    "    cy = np.sum(y * yp) / np.sum(yp)\n",
    "    sx = np.sqrt(np.sum(((x - cx) ** 2) * xp) / np.sum(img))\n",
    "    sy = np.sqrt(np.sum(((y - cy) ** 2) * yp) / np.sum(img))\n",
    "    skewx = np.sum(xp * ((x - cx) ** 3)) / (np.sum(img) * sx ** 3)\n",
    "    skewy = np.sum(yp * ((y - cy) ** 3)) / (np.sum(img) * sy ** 3)\n",
    "    kurtx = np.sum(xp * ((x - cx) ** 4)) / (np.sum(img) * sx ** 4) - 3\n",
    "    kurty = np.sum(yp * ((y - cy) ** 4)) / (np.sum(img) * sy ** 4) - 3\n",
    "    return (skewx, skewy), (kurtx, kurty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bb86df9-e456-41b3-8f96-7310c90f55e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image_path):\n",
    "    img = io.imread(image_path)\n",
    "    img = preproc(img)\n",
    "    ratio = Ratio(img)\n",
    "    cent_y, cent_x = Centroid(img)\n",
    "    eccentricity, solidity = EccentricitySolidity(img)\n",
    "    skewx, skewy = SkewKurtosis(img)[0]\n",
    "    kurtx, kurty = SkewKurtosis(img)[1]\n",
    "    return [ratio, cent_y, cent_x, eccentricity, solidity, skewx, skewy, kurtx, kurty]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b954ac41-4a65-4aeb-a204-e3269a41818b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Prepare Dataset\n",
    "def prepare_dataset():\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    # Loop over each dataset (dataset1, dataset2, etc.)\n",
    "    for dataset in datasets:\n",
    "        genuine_path = os.path.join(base_path, dataset, 'real')\n",
    "        forged_path = os.path.join(base_path, dataset, 'forge')\n",
    "        \n",
    "        # Loop over each image in genuine and forged folder\n",
    "        for img_name in os.listdir(genuine_path):\n",
    "            img_path = os.path.join(genuine_path, img_name)\n",
    "            data.append(extract_features(img_path))\n",
    "            labels.append(1)  # Genuine = 1\n",
    "\n",
    "        for img_name in os.listdir(forged_path):\n",
    "            img_path = os.path.join(forged_path, img_name)\n",
    "            data.append(extract_features(img_path))\n",
    "            labels.append(0)  # Forged = 0\n",
    "\n",
    "    return np.array(data), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fc86bed-b02b-44b1-8aeb-e56f7720ad33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset\n",
    "X, y = prepare_dataset()\n",
    "X = X / np.max(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a111bfd-0689-443c-8d66-a261b6937527",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 4: Build and Compile Model (Neural Network)\n",
    "def build_model(input_dim):\n",
    "    model = Sequential([\n",
    "        Input(shape=(input_dim,)),  # ✅ use shape instead of input_shape\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "763f9e62-81f9-4195-a518-f1141b90aca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Step 5: Train Model\n",
    "def train_model(X, y):\n",
    "    \n",
    "\n",
    "    model = build_model(X.shape[1])\n",
    "    \n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    \n",
    "    model.fit(X_train, y_train,\n",
    "              validation_data=(X_val, y_val),\n",
    "              epochs=50,\n",
    "              batch_size=16,\n",
    "              callbacks=[early_stop],\n",
    "              verbose=1)\n",
    "    \n",
    "    # ✅ Save using the newer .keras format\n",
    "    model.save(\"signature_model.keras\")\n",
    "    print(\"✅ Model saved as 'signature_model.keras'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9e45add-9037-40f1-81b7-4115c492e894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Load and Predict on Batched Input (to avoid retracing warning)\n",
    "def predict_signature_batch(image_paths):\n",
    "    from tensorflow.keras.models import load_model\n",
    "    model = load_model(\"signature_model.keras\")\n",
    "\n",
    "    # ✅ Compile after loading if evaluating\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    features = [extract_features(img_path) for img_path in image_paths]\n",
    "    features = np.array(features)\n",
    "\n",
    "    predictions = model.predict(features, batch_size=4, verbose=0)\n",
    "    for i, pred in enumerate(predictions):\n",
    "        label = \"Genuine\" if pred > 0.5 else \"Forged\"\n",
    "        print(f\"{image_paths[i]} ➜ {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3c428a7-1b8b-4a0a-bda9-f98ad91f3afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.5069 - loss: 0.6938 - val_accuracy: 0.5139 - val_loss: 0.6938\n",
      "Epoch 2/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5286 - loss: 0.6929 - val_accuracy: 0.5833 - val_loss: 0.6913\n",
      "Epoch 3/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5587 - loss: 0.6905 - val_accuracy: 0.5694 - val_loss: 0.6896\n",
      "Epoch 4/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5619 - loss: 0.6880 - val_accuracy: 0.5486 - val_loss: 0.6890\n",
      "Epoch 5/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5419 - loss: 0.6903 - val_accuracy: 0.6042 - val_loss: 0.6860\n",
      "Epoch 6/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5458 - loss: 0.6872 - val_accuracy: 0.5972 - val_loss: 0.6841\n",
      "Epoch 7/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5553 - loss: 0.6849 - val_accuracy: 0.5972 - val_loss: 0.6822\n",
      "Epoch 8/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5221 - loss: 0.6848 - val_accuracy: 0.6111 - val_loss: 0.6793\n",
      "Epoch 9/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5583 - loss: 0.6819 - val_accuracy: 0.6111 - val_loss: 0.6784\n",
      "Epoch 10/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5355 - loss: 0.6856 - val_accuracy: 0.6181 - val_loss: 0.6759\n",
      "Epoch 11/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5519 - loss: 0.6826 - val_accuracy: 0.6319 - val_loss: 0.6742\n",
      "Epoch 12/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5877 - loss: 0.6749 - val_accuracy: 0.6042 - val_loss: 0.6712\n",
      "Epoch 13/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5652 - loss: 0.6763 - val_accuracy: 0.6111 - val_loss: 0.6705\n",
      "Epoch 14/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6050 - loss: 0.6736 - val_accuracy: 0.5903 - val_loss: 0.6686\n",
      "Epoch 15/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5527 - loss: 0.6762 - val_accuracy: 0.6042 - val_loss: 0.6669\n",
      "Epoch 16/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5829 - loss: 0.6655 - val_accuracy: 0.6319 - val_loss: 0.6641\n",
      "Epoch 17/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6338 - loss: 0.6556 - val_accuracy: 0.5972 - val_loss: 0.6646\n",
      "Epoch 18/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.5802 - loss: 0.6670 - val_accuracy: 0.6250 - val_loss: 0.6614\n",
      "Epoch 19/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5898 - loss: 0.6601 - val_accuracy: 0.6597 - val_loss: 0.6598\n",
      "Epoch 20/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6280 - loss: 0.6569 - val_accuracy: 0.6181 - val_loss: 0.6624\n",
      "Epoch 21/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5939 - loss: 0.6550 - val_accuracy: 0.6181 - val_loss: 0.6617\n",
      "Epoch 22/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6305 - loss: 0.6551 - val_accuracy: 0.6528 - val_loss: 0.6554\n",
      "Epoch 23/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5999 - loss: 0.6574 - val_accuracy: 0.6528 - val_loss: 0.6544\n",
      "Epoch 24/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.6012 - loss: 0.6488 - val_accuracy: 0.6319 - val_loss: 0.6510\n",
      "Epoch 25/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6220 - loss: 0.6490 - val_accuracy: 0.6181 - val_loss: 0.6541\n",
      "Epoch 26/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6127 - loss: 0.6443 - val_accuracy: 0.6597 - val_loss: 0.6485\n",
      "Epoch 27/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6418 - loss: 0.6351 - val_accuracy: 0.6319 - val_loss: 0.6498\n",
      "Epoch 28/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6267 - loss: 0.6407 - val_accuracy: 0.6181 - val_loss: 0.6530\n",
      "Epoch 29/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6192 - loss: 0.6484 - val_accuracy: 0.6667 - val_loss: 0.6459\n",
      "Epoch 30/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6079 - loss: 0.6444 - val_accuracy: 0.6181 - val_loss: 0.6470\n",
      "Epoch 31/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6442 - loss: 0.6287 - val_accuracy: 0.6319 - val_loss: 0.6435\n",
      "Epoch 32/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6262 - loss: 0.6338 - val_accuracy: 0.6806 - val_loss: 0.6488\n",
      "Epoch 33/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6521 - loss: 0.6399 - val_accuracy: 0.6736 - val_loss: 0.6429\n",
      "Epoch 34/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6357 - loss: 0.6297 - val_accuracy: 0.6458 - val_loss: 0.6420\n",
      "Epoch 35/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6446 - loss: 0.6323 - val_accuracy: 0.6389 - val_loss: 0.6460\n",
      "Epoch 36/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6259 - loss: 0.6444 - val_accuracy: 0.6875 - val_loss: 0.6422\n",
      "Epoch 37/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6416 - loss: 0.6146 - val_accuracy: 0.6458 - val_loss: 0.6398\n",
      "Epoch 38/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6527 - loss: 0.6190 - val_accuracy: 0.7153 - val_loss: 0.6361\n",
      "Epoch 39/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.6413 - loss: 0.6263 - val_accuracy: 0.6458 - val_loss: 0.6431\n",
      "Epoch 40/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6241 - loss: 0.6360 - val_accuracy: 0.6806 - val_loss: 0.6358\n",
      "Epoch 41/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.6710 - loss: 0.6343 - val_accuracy: 0.6736 - val_loss: 0.6364\n",
      "Epoch 42/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6692 - loss: 0.6211 - val_accuracy: 0.6736 - val_loss: 0.6321\n",
      "Epoch 43/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6576 - loss: 0.6288 - val_accuracy: 0.7014 - val_loss: 0.6373\n",
      "Epoch 44/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6673 - loss: 0.6067 - val_accuracy: 0.6944 - val_loss: 0.6364\n",
      "Epoch 45/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6524 - loss: 0.6142 - val_accuracy: 0.6806 - val_loss: 0.6318\n",
      "Epoch 46/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6926 - loss: 0.6013 - val_accuracy: 0.6111 - val_loss: 0.6548\n",
      "Epoch 47/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6506 - loss: 0.6411 - val_accuracy: 0.6806 - val_loss: 0.6287\n",
      "Epoch 48/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6615 - loss: 0.6159 - val_accuracy: 0.7014 - val_loss: 0.6350\n",
      "Epoch 49/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6447 - loss: 0.6069 - val_accuracy: 0.6458 - val_loss: 0.6376\n",
      "Epoch 50/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6315 - loss: 0.6370 - val_accuracy: 0.6458 - val_loss: 0.6373\n",
      "✅ Model saved as 'signature_model.keras'\n"
     ]
    }
   ],
   "source": [
    "train_model(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a120e70-be31-4e6f-8411-918d4215e89f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate_model(X_test, y_test):\n",
    "    model = load_model('signature_model.keras')  # ✅ updated format\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])  # ensure metrics work\n",
    "    y_pred = model.predict(X_test, batch_size=4)  # ✅ batch prediction to avoid retracing\n",
    "    y_pred = (y_pred > 0.5).astype(int)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Predict a single signature\n",
    "def predict_signature(image_path):\n",
    "    model = load_model('signature_model.keras')  # ✅ updated format\n",
    "    features = np.array(extract_features(image_path)).reshape(1, -1)\n",
    "    pred = model.predict(features, batch_size=1)  # ✅ batch_size added\n",
    "    print(f\"{image_path} ➜ {'Genuine' if pred[0][0] > 0.5 else 'Forged'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1beca45a-3130-4af7-a3ea-2c649c5d26fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "with open(\"signature_utils.py\", \"w\") as f:\n",
    "    f.write(inspect.getsource(extract_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d114eed6-a6a1-4a5b-b75e-c8d97f0c4b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.80      0.72        74\n",
      "           1       0.72      0.56      0.63        70\n",
      "\n",
      "    accuracy                           0.68       144\n",
      "   macro avg       0.69      0.68      0.67       144\n",
      "weighted avg       0.69      0.68      0.68       144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# After splitting your dataset\n",
    "evaluate_model(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "502b5a72-ca71-458e-b38d-9923b066d765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step\n",
      "dataset/dataset2/real/00101001.png ➜ Genuine\n"
     ]
    }
   ],
   "source": [
    "predict_signature(\"dataset/dataset2/real/00101001.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5298fa8b-d287-43b9-9c93-7a4c728cbe7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step\n",
      "dataset/dataset1/forge/02100002.png ➜ Forged\n"
     ]
    }
   ],
   "source": [
    "predict_signature(\"dataset/dataset1/forge/02100002.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c878b51c-3a67-4633-be94-75c942688860",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a266fc88-aff9-4135-b1e4-71efd317e572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57778f4b-6edb-4d60-bf4a-ae5e959567db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ffc8af-8c1a-4076-b1cf-d21c3f0ae773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42608d72-1b5d-418a-9051-04673ba35bff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab319a8-8b04-4bd9-9d6f-01fb90399a53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ae211b-0718-4a0e-85d7-64462f06fd44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc9a41e-c29c-4349-97ba-6c4ef2a27d40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0cda04-d407-491e-b97d-f4361c0296bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9d0e2a-1917-4038-a406-25ca5d0ce35f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33c81a0-17d8-45c3-acb1-855d4dc40ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d52b04e-84e1-4ce2-8623-0f45e7391cce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ccf48b-e655-47e0-8d17-266e761d8620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d49bb6-2208-44fe-bb11-7810275fcc60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab3051c-6383-4dea-9b08-f1e9032fe23e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4897a3d1-91fb-4da3-b216-3d9ca935b01e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546acec6-1995-4b84-9ec7-562237a53687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a9c803-0124-4589-842e-0887b844d322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72245e9-77fc-43c3-817c-81a4867ad53e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5b580d-8520-4b71-a3d2-30dbc5922b53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
